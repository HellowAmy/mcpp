# 分兵三路


## 多线程的意义
#### main.cpp
~~~
#include <iostream>
#include <thread>
#include <atomic>
#include <memory>
#include <mutex>
#include <memory>
#include <chrono>

#include "mclog.h"

// 一百万
int count_100w = 100 * 10000;

// 无锁累加变量
int num = 0;

// 原子累加变量
std::atomic<int> atm_num(0);

// 使用 mutex 上锁的普通变量
int num_lock = 0;
std::mutex mut;

// 测试不同类型运算的多线程函数
void work_add_th()
{
    for (int i = 0; i < count_100w; i++)
    {
        num++;
    }
    MCLOG("work_add 结束");
}
void work_sub_th()
{
    for (int i = 0; i < count_100w; i++)
    {
        num--;
    }
    MCLOG("work_sub 结束");
}
void work_add_atomic_th()
{
    for (int i = 0; i < count_100w; i++)
    {
        atm_num++;
    }
    MCLOG("work_add_atomic 结束");
}
void work_sub_atomic_th()
{
    for (int i = 0; i < count_100w; i++)
    {
        atm_num--;
    }
    MCLOG("work_sub_atomic 结束");
}

void work_add_lock_th()
{
    for (int i = 0; i < count_100w; i++)
    {
        // lock 会在下一行代码上锁，离开作用域自己解锁
        // 在这个 for 循环中，每一个循环都是单独的作用域，会自动上锁和解锁一次
        std::lock_guard<std::mutex> lock(mut);
        num_lock++;
    }
    MCLOG("work_add_lock 结束");
}
void work_sub_lock_th()
{
    for (int i = 0; i < count_100w; i++)
    {
        std::lock_guard<std::mutex> lock(mut);
        num_lock--;
    }
    MCLOG("work_sub_lock 结束");
}

int main(int argc, char **argv)
{
    // 线程的意义
    MCLOG("单线程与多线程速度对比");
    {
        using namespace std::chrono;

        // 1 亿
        int count_100m = 10 * 10000 * 10000;

        // 单线程速度
        {
            auto btime = steady_clock::now();
            long long sum = 0;
            for (int i = 0; i < count_100m; i++)
            {
                sum += i;
            }
            auto etime = duration_cast<milliseconds>(steady_clock::now() - btime).count();
            MCLOG("单线程毫秒 " $(etime) $(sum));
        }

        // 多线程速度
        {
            auto btime = steady_clock::now();
            int half = count_100m / 2;
            long long sum_fisrt = 0;
            long long sum_second = 0;

            // 多线程计算
            std::thread th1([&]() {
                long long sum_fisrt_1 = 0;
                for(int i=0;i<half;i++)
                {   
                    sum_fisrt_1+=i;
                }
                sum_fisrt = sum_fisrt_1; 
            });
            std::thread th2([&]() {
                long long sum_fisrt_2 = 0;
                for(int i=half;i<count_100m;i++)
                {   
                    sum_fisrt_2+=i;
                }
                sum_second = sum_fisrt_2; 
            });

            // 等待同步
            th1.join();
            th2.join();
            long long sum = sum_fisrt + sum_second;

            auto etime = duration_cast<milliseconds>(steady_clock::now() - btime).count();
            MCLOG("多线程毫秒 " $(etime) $(sum));
        }
    }

    // 线程的未知数
    MCLOG("\n多线程数据竞争问题");
    {
        MCLOG("无锁多线程启动");
        std::thread th_add(work_add_th);
        std::thread th_sub(work_sub_th);

        MCLOG("等待线程");
        th_add.join();
        th_sub.join();
        MCLOG("执行完毕 " $(num));
    }
    {
        MCLOG("\n原子变量多线程启动");
        std::thread th_add(work_add_atomic_th);
        std::thread th_sub(work_sub_atomic_th);

        MCLOG("等待线程");
        th_add.join();
        th_sub.join();
        MCLOG("执行完毕 " $(atm_num));
    }
    {
        MCLOG("\n上锁多线程启动");
        std::thread th_add(work_add_lock_th);
        std::thread th_sub(work_sub_lock_th);

        MCLOG("等待线程");
        th_add.join();
        th_sub.join();
        MCLOG("执行完毕 " $(num_lock));
    }
    return 0;
}
~~~

#### 打印结果
~~~
单线程与多线程速度对比 [/home/red/open/github/mcpp/example/19/main.cpp:82]
单线程毫秒 [etime: 1873] [sum: 499999999500000000]  [/home/red/open/github/mcpp/example/19/main.cpp:98]
多线程毫秒 [etime: 951] [sum: 499999999500000000]  [/home/red/open/github/mcpp/example/19/main.cpp:132]

多线程数据竞争问题 [/home/red/open/github/mcpp/example/19/main.cpp:137]
无锁多线程启动 [/home/red/open/github/mcpp/example/19/main.cpp:139]
等待线程 [/home/red/open/github/mcpp/example/19/main.cpp:143]
work_sub 结束 [/home/red/open/github/mcpp/example/19/main.cpp:39]
work_add 结束 [/home/red/open/github/mcpp/example/19/main.cpp:31]
执行完毕 [num: 868630]  [/home/red/open/github/mcpp/example/19/main.cpp:146]

原子变量多线程启动 [/home/red/open/github/mcpp/example/19/main.cpp:149]
等待线程 [/home/red/open/github/mcpp/example/19/main.cpp:153]
work_add_atomic 结束 [/home/red/open/github/mcpp/example/19/main.cpp:47]
work_sub_atomic 结束 [/home/red/open/github/mcpp/example/19/main.cpp:55]
执行完毕 [atm_num: 0]  [/home/red/open/github/mcpp/example/19/main.cpp:156]

上锁多线程启动 [/home/red/open/github/mcpp/example/19/main.cpp:159]
等待线程 [/home/red/open/github/mcpp/example/19/main.cpp:163]
work_sub_lock 结束 [/home/red/open/github/mcpp/example/19/main.cpp:76]
work_add_lock 结束 [/home/red/open/github/mcpp/example/19/main.cpp:67]
执行完毕 [num_lock: 0]  [/home/red/open/github/mcpp/example/19/main.cpp:166]
~~~

多线程和单线程，这一部分应该是新手入门编程需要接触的最后一部分了，这意味则这个系列的文章已经接近尾声  
在前面的代码中，代码的运行总是顺序执行的，像一条流水线一样一步步的执行，但多线程却不是如此，他们是同时执行的  
同时实行是一件好事，也是一件坏事，好的是速度更快，坏的是数据可能会损坏，当然这里的损坏只是值数据的计算和预期不一致  

#### 速度加倍

在 main.cpp 的第一部分代码中，我计算了一个亿的累加，从结果上看，这个数据在单线程和多线程的时间差了一倍  
我把一个亿的数，拆成了两个部分，启动了两个线程分别对上半部和下半部进行运行，最后将结果累加到一起，可以看出结果是一样的，但速度快了一倍  
这就是多线程的好处，它可以让一个运算拆成多个部分同时进行，让速度更快  

#### 奇怪的结果
~~~
// 线程共享数据 
int num = 100;

// 两个线程从共享数据中取值
int tmadd = num;
int tmsub = num;

// 假设多线程的运行步骤
tmadd =  100 + 1 = 101;     // 加法执行中 - 线程加步骤
tmsub =  100 - 1 = 99;      // 减法执行中 - 线程减步骤（穿插在加法运算之间）
num = tmsub                 // 减法赋值 num = 99 - 线程减步骤（穿插在加法运算之间）
num = tmadd                 // 加法赋值 num = 101 - 线程加步骤，最终结果为 101 ，因为 99 的值被 101 覆盖

// 如果被上锁会强制执行运算顺序
tmadd =  100 + 1 = 101;     // 加法执行中 - 线程加步骤
int tmsub = num;            // 减法执行中 - 获取上锁数据，等到解锁 - 线程减步骤
num = tmadd                 // 加法赋值 num = 101 - 线程加步骤
int tmsub = num;            // 减法执行中 - 已解锁，重新尝试获取数据 
tmsub =  101 - 1 = 100;     // 减法执行中 - 运算结果
num = tmsub                 // 减法赋值 num = 100，最终结果是正确的顺序
~~~

当然，多线程也有一些问题，正如前面所说，多线是好事也是坏事，多线程编程会让代码变得更复杂且危险  
你可以看到，在 main.cpp 第二部分中的 work_add_th work_sub_th 两个函数运行在多线程上，可以看出来他们的执行结果等于 0 ，但是在多线程中并非如此，最后的执行结果变成了随机值  
造成这个问题的是多线程的数据竞争问题，也是造成数据损坏的原因，即运算结果和预期不符   
多线程的数据竞争是一个很有趣的事情，在 work_add_th 函数会使得变量 num 加一，假设 num 此时为 100，那运算结果为 101，但是在 100 和 101 中间，如果刚好完整的执行了 work_sub_th 函数减一，此时 num 的值会变成 99 ，那 work_add_th 的执行结果应该是 99 + 1 = 100 才行，但实际上的结果会变成 99 + 1 = 101 ，一个很奇怪的现象，他们一共执行了两次，但确是执行一次的效果    
其实这个现象不难理解，因为 num 是一个内存，他的运行本身在CPU上的CPU会需要提取内存到自己的缓存中，此时就会出现两份的 num 数据，CPU取得这个内存进行运算之后，重复赋值回到 num 这一块内存，但如果有多个CPU同时对 num 运算，却没有规定赋值的顺序，就会造成随机的赋值结果    
通常一个线程可以理解为独立的CPU，这意味着有多少和线程就有多少分 num 内存副本在CPU上，一旦他们的赋值顺序不一致就会造成数据损坏  
这种多个CPU操作一份数据导致数据损坏的结果称为数据竞争，而需要上锁保护的数据称为临界点    
上锁的机制很简单，就是强制CPU必须要运算完成被上锁的共享数据，其他线程才能接管被上锁的数据，其他线程的执行不能穿插在被上锁的数据中间，可以保证这个数据是完整的顺序的运算，这种操作称为原子操作   

#### 线程标识

运行在多线程的函数通常是危险的，通常会称为临界点，所以运行在线程中的函数或者变量最后给他们打上标记，这样当你要修改与线程相关的代码时，看到这个标记就会有所警觉，否则一旦你忘记了这是线程函数，以普通函数对待时，就可能引起数据竞争的问题    
标记多线程函数是 **编程规范** 的重要一步
我习惯打一个 th 的标识在函数中，这样可以让我更谨慎的对待这些函数，不至于犯下一些愚蠢的操作   


## 锁和多线程
#### 原子变量

在C++的多线程中，如果只是针对单个数据上锁，可以使用 std::atomic 原子变量，它是一种无锁结构的互斥量，如果你只需要对基本的数据类型或者简单的结构体进行上锁，都可以使用 atomic ，因为它是支持模板的  
原子变量的使用非常普遍，因为它是一种高效的等待技术，实现CPU顺序执行的逻辑有两种，一种是在线程空转，直到修改成功，一种是线程休眠，直到被唤醒，atomic 采用的是空转的方式  
线程空转指的是，如果无法修改就一直尝试修改，直到成功，这种方法相对更快  
线程休眠指的是，如果到你执行了，你会从休眠中醒来，醒来时代表到你操作，这种方式会有线程切换的时间会慢一些      
不管采用哪一种方式，你应该尽可能的降低修改共享数据的次数，以及上锁的时间   

#### 上锁

上锁采用的是 std::mutex 变量，注意这个类型是不可赋值的，它被称为互斥量，意味着同一个 mutex 上锁的区域一定是顺序执行的  
使用 mutex 上锁的好处是它可以对多行代码进行上锁，而不仅仅是变量，你可以上锁在 mutex 范围内调用函数等，都可以保证是顺序执行的  
使用 mutex 是我习惯于借助 std::lock_guard std::unique_lock 等自动解锁的方式来控制 mutex 的上锁范围  
比如 lock_guard 他可以在创建是上锁，释放是解锁，类似与自能指针，它总是可以帮助我们对上锁的区域进行解锁，而不用担心忘记解锁的事情  
一个值得注意的事情，如果你忘记解锁了，那你的代码会永远的卡在下一个请求上锁的位置，这是一个非常严重的疏忽   

#### 死锁危险
~~~
int num_die = 0;
std::mutex muta;
std::mutex mutb;

void fun_a()
{
    std::lock_guard<std::mutex> locka(muta); // 线程 a 成功获取
    std::lock_guard<std::mutex> lockb(mutb); // 被线程 b 占用，等待释放，进入休眠
    num_die += 1;
}
void fun_b()
{
    std::lock_guard<std::mutex> lockb(mutb); // 线程 b 成功获取
    std::lock_guard<std::mutex> locka(muta); // 被线程 a 占用，等待释放，进入休眠
    num_die += 2;
}
~~~

我们采用 mutex 给代码上锁，为了速度考量，通常上锁的区域都很小，不同的共享数据都需要单独为我们配上专属的 mutex 互斥量，当你的线程中出现多个 mutex 时就要小心了，他们可能会造成死锁，一旦形成死锁线程将会永远卡在上锁的位置    
死锁就是存在多个 mutex 交叉上锁的现象，假设存在 A B 两个锁，函数同时获取这两个锁才能安全的操作数据，如果函数获取了 A 锁，正在获取 B 锁，于此同时另一个函数获取了 B 锁，等待获取 A 锁，那么这两个线程就都尬住了，他们同时进入休眠，也都同时等待另一个线程释放，也就是说谁都不会释放，也谁都醒不来，这就是死锁  
解决这种事情的方式很简单，只需要让他们获取锁的顺序一致就可以了，但是这种需要多层嵌套的锁本身就很危险，不应该让嵌套锁出现，或者你应该使用超时锁，超时会自己释放也许代码还能继续运行   
死锁是非常危险的，但是避免死锁其实也很简单，就是尽量不要嵌套上锁，一旦出现嵌套上锁时，你就应该需要考虑拆分代码，而不是检查是否会发生死锁     
除了两个锁相互嵌套之外，单锁的递归上锁也会造成死锁，不过在递归中上锁也是神奇，我愿称为愚蠢的代码，因为很多时候换一种设计方式就该避免不必要的麻烦   

#### 无锁技术

上面提到的 atomic 原子变量采用的是一种无锁技术，这种技术是高性能多线程的关键，虽然新手完全不用在意，但还是希望你能了解到  
无锁技术 CAS 是一种让线程不休眠就可以实现互斥的技术，可以减少切换线程带来的性能损失  
简单来说就是线程中需要连续执行多个步骤并保证顺序，比如需要使用十步来修改共享数据，如果不使用 mutex 那多线程下大概率是乱序执行的  
无锁技术会在执行第一步时检查共享数据，然后执行十步，执行完毕之后检查共享数据是否被修改，如果被修改说明有其他线程也在执行这步操作，赋值取消，重新执行十步，直到发现共享数据没有被修改，说明是顺序的，中途没有被其他线程修改，结果可用赋值给共享变量       
这个方式看描述看上去很愚蠢，实际上并没有描述的那样，因为无锁技术只需要在需要共享的位置重新推算即可，而不是全部推倒重来，当然无锁获取了更快的速度，也增加了复杂度   
无锁技术会依赖与 compare_exchange_weak std::memory_order_release 等交换函数和内存顺序声明来确保共享数据的修改状态，他们需要同步不同CPU之间的共享数据副本的数据，因为多线程下，数据的副本并不会同步的，如果数据不同步就会造成数据的损坏  
其中 compare_exchange_weak 函数来检查一开始的共享数据，如果相同则交换，不同则放弃，这是函数是安全交换共享数据的关键，因为在多线程中修改共享数据是危险的，而 std::memory_order_release 为更新内存顺序的标记，它声明了所有内存顺序中，到这一步为止都是正确的，它且保了修改的共享数据是最新的  


## 项目路径
~~~
https://github.com/HellowAmy/mcpp.git
~~~